/**
 * Zod schemas and types for sampler common structures
 *
 * Single source of truth for chunking, vignettes, and sampler state.
 * Types are exported using z.infer to guarantee runtime/compile-time consistency.
 */

import {z} from 'zod';

import {EMBEDDING_DIMENSION} from './embedder';

/**
 * Text chunk with position metadata
 *
 * Represents a segment of text extracted from the original data with
 * character offsets preserved for reference back to the source.
 */
export const ChunkSchema = z.object({
	/**
	 * Chunk content (trimmed)
	 */
	content: z.string().describe('Chunk content (trimmed)'),

	/**
	 * Character offset in original text (before trim)
	 */
	start: z.number().int().min(0).describe('Character offset in original text (before trim)'),

	/**
	 * Character offset in original text (before trim)
	 */
	end: z.number().int().min(0).describe('Character offset in original text (before trim)'),
});

export type Chunk = z.infer<typeof ChunkSchema>;

/**
 * Position of a vignette in the original data
 *
 * Character offsets allow mapping vignettes back to their source location.
 */
export const VignettePositionSchema = z.object({
	/**
	 * Character offset where content starts
	 */
	start: z.number().int().min(0).describe('Character offset where content starts'),

	/**
	 * Character offset where content ends
	 */
	end: z.number().int().min(0).describe('Character offset where content ends'),
});

export type VignettePosition = z.infer<typeof VignettePositionSchema>;

/**
 * A vignette is a text snippet with its embedding and position in the original data
 *
 * Used by the Analyser Agent to examine diverse samples of the data without
 * processing the entire dataset. Embeddings enable diversity-based sampling.
 */
export const VignetteSchema = z.object({
	/**
	 * Text content of the vignette
	 */
	content: z.string().describe('Text content of the vignette'),

	/**
	 * Position in the original raw data (before trimming)
	 */
	position: VignettePositionSchema.describe('Position in the original raw data (before trimming)'),

	/**
	 * 384-dimensional embedding vector
	 *
	 * Generated by all-MiniLM-L6-v2 model, normalised for cosine similarity.
	 */
	embedding: z
		.array(z.number())
		.length(EMBEDDING_DIMENSION)
		.describe('384-dimensional embedding vector from all-MiniLM-L6-v2'),
});

export type Vignette = z.infer<typeof VignetteSchema>;

/**
 * State maintained across sampling operations
 *
 * Allows incremental sampling - the agent can request more samples without
 * reprocessing the entire dataset. Tracks which chunks have already been provided.
 *
 * Note: Embeddings are expensive to compute, so we preserve them across attempts.
 */
export const SamplerStateSchema = z.object({
	/**
	 * Original input data (untrimmed)
	 *
	 * Preserved for position reference and potential future sampling.
	 */
	rawData: z.string().describe('Original input data (untrimmed)'),

	/**
	 * All chunks with position metadata
	 *
	 * Computed once during initial sampling, reused for subsequent requests.
	 */
	allChunks: z.array(ChunkSchema).describe('All chunks with position metadata'),

	/**
	 * All embeddings corresponding to allChunks
	 *
	 * 384-dimensional vectors in same order as allChunks.
	 * Computed once during initial sampling, reused for subsequent requests.
	 */
	allEmbeddings: z
		.array(z.array(z.number()).length(EMBEDDING_DIMENSION))
		.describe('All embeddings corresponding to allChunks'),

	/**
	 * Indices of chunks already provided to the agent
	 *
	 * Used to ensure no duplicate vignettes are sent. Indices correspond
	 * to positions in allChunks and allEmbeddings arrays.
	 */
	providedIndices: z.set(z.number().int().min(0)).describe('Indices of chunks already provided to the agent'),
});

export type SamplerState = z.infer<typeof SamplerStateSchema>;
